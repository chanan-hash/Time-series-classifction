{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72140b69-44a0-4e4e-b04c-7db9271affeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chanan/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/chanan/miniconda3/envs/myenv/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from momentfm import MOMENTPipeline\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib as plt\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "config = Namespace(\n",
    "    batch_size=32,\n",
    "    num_epochs=50,\n",
    "    learning_rate=1e-4,\n",
    "    seq_len=101,  # Your sequence length\n",
    "    n_channels=1,\n",
    "    num_class=5,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a560b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a6dfcc-f73e-41a3-bb81-69f6e4c6fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 951/951 [00:00<00:00, 1.81MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 1.39G/1.39G [00:32<00:00, 42.4MB/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 19.61 GiB of which 5.44 MiB is free. Process 295107 has 18.09 GiB memory in use. Including non-PyTorch memory, this process has 1.48 GiB memory in use. Of the allocated memory 1.30 GiB is allocated by PyTorch, and 9.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MOMENTPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutonLab/MOMENT-1-large\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     }\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 903 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 19.61 GiB of which 5.44 MiB is free. Process 295107 has 18.09 GiB memory in use. Including non-PyTorch memory, this process has 1.48 GiB memory in use. Of the allocated memory 1.30 GiB is allocated by PyTorch, and 9.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\", \n",
    "    model_kwargs={\n",
    "        'task_name': 'classification',\n",
    "        'n_channels': config.n_channels,\n",
    "        'num_class': config.num_class\n",
    "    }\n",
    ")\n",
    "model.init()\n",
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Plot and save confusion matrix\"\"\"\n",
    "    save_dir=config.checkpoint_dir\n",
    "    classes = config.classes_names\n",
    "    try:\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            print(f\"Created directory: {save_dir}\")\n",
    "        \n",
    "        print(f\"\\nCreating confusion matrix...\")\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        # Add class labels\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45, ha='right')\n",
    "        plt.yticks(tick_marks, classes)\n",
    "        \n",
    "        # Add text annotations\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in np.ndindex(cm.shape):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        \n",
    "        \n",
    "        # Save path with full directory\n",
    "        save_path = os.path.join(save_dir, f'{config.model_name}_confusion_matrix.png')\n",
    "        print(f\"Saving confusion matrix to: {save_path}\")\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(\"Successfully saved confusion matrix\")\n",
    "        \n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "        \n",
    "        # Close\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in plotting confusion matrix: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb45fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"Plot and save training metrics\"\"\"\n",
    "    save_dir=config.os.path.dirname(os.path.abspath(__file__))\n",
    "    try:\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            print(f\"Created directory: {save_dir}\")\n",
    "        else:\n",
    "            print(f\"Directory already exists: {save_dir}\")\n",
    "        \n",
    "        print(\"\\nPlotting Training Metrics...\")\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot losses\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot accuracies\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_accs, label='Training Accuracy')\n",
    "        plt.plot(val_accs, label='Validation Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        \n",
    "        # Save path with full directory\n",
    "        save_path = os.path.join(save_dir, f'{config.model_name}_training_metrics.png')\n",
    "        print(f\"Saving metrics plot to: {save_path}\")\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(\"Successfully saved metrics plot\")\n",
    "        \n",
    "        \n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "        \n",
    "        #close\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in plotting metrics: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9da2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        test_loader: DataLoader for test data\n",
    "        config: Configuration object\n",
    "        classes: List of class names (optional)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            if config.use_gpu:\n",
    "                batch_x = batch_x.float().cuda()\n",
    "                batch_y = batch_y.long().cuda()\n",
    "            \n",
    "            # Create marking tensor with correct dimensions (batch_size, seq_len, 1)\n",
    "            # batch_mark = torch.ones((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2]), device=batch_x.device)\n",
    "\n",
    "            outputs = model(\n",
    "                x_enc=batch_x,\n",
    "                x_mark_enc= None,#batch_mark,\n",
    "                x_dec=None,\n",
    "                x_mark_dec=None\n",
    "            )\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            # all_preds.extend(predicted.cpu().numpy())\n",
    "            # all_labels.extend(batch_y.cpu().numpy())\n",
    "            \n",
    "            all_preds.extend(predicted.cuda().numpy())\n",
    "            all_labels.extend(batch_y.cuda().numpy())\n",
    "    \n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Val Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    eval_time = end_time - start_time\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(all_labels, all_preds, config)\n",
    "    \n",
    "    print(f\"\\nEvaluation Complete!\")\n",
    "    print(f\"Total evaluation time: {timedelta(seconds=eval_time)}\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc16fb-d17d-4ab8-9e1c-18a074ed17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    for batch_data, batch_labels in progress_bar:\n",
    "        # # Reshape data to [batch_size, n_channels, seq_len]\n",
    "        # batch_data = batch_data.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        # Move to device\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model.classify(x_enc=batch_data)\n",
    "        loss = criterion(outputs.logits, batch_labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        correct += (predictions == batch_labels).sum().item()\n",
    "        total += batch_labels.size(0)\n",
    "        \n",
    "        # Update total loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{total_loss/(progress_bar.n+1):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc='Validation')\n",
    "        for batch_data, batch_labels in progress_bar:\n",
    "            # # Reshape data\n",
    "            # batch_data = batch_data.unsqueeze(1)\n",
    "            \n",
    "            # Move to device\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model.classify(x_enc=batch_data)\n",
    "            loss = criterion(outputs.logits, batch_labels)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (predictions == batch_labels).sum().item()\n",
    "            total += batch_labels.size(0)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{total_loss/(progress_bar.n+1):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return total_loss / len(val_loader), correct / total\n",
    "\n",
    "# Main training loop\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    # Start timing\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(config.num_epochs):        \n",
    "        print(f'\\nEpoch {epoch+1}/{config.num_epochs}')\n",
    "\n",
    "        # Epoch train time\n",
    "        epoch_start_time = time.time()\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, config.device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(\n",
    "            model, val_loader, criterion, config.device\n",
    "        )\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%')\n",
    "        print(f'Epoch time: {timedelta(seconds=int(epoch_time))}')\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict()\n",
    "            print(f'New best validation accuracy: {best_val_acc*100:.2f}%')\n",
    "\n",
    "    # Calculate total training time\n",
    "    total_time = time.time() - total_start_time\n",
    "    print(\"\\nTraining Complete!\")\n",
    "    print(f\"Total training time: {timedelta(seconds=total_time)}\")\n",
    "\n",
    "     # Plot and save metrics\n",
    "    plot_metrics(train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "    # Infrence\n",
    "    evaluate_model(model, val_loader)\n",
    "    \n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293d9c3f-9f44-48f3-a1af-65da8e6a08a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5737,)\n",
      "(5737, 101, 1)\n",
      "(5737,)\n"
     ]
    }
   ],
   "source": [
    "def drop_unused_features(df, num_features, pos):\n",
    "    \"\"\"\n",
    "    Drops all columns except those at positions pos and then repeats for every num_features columns\n",
    "    \"\"\"\n",
    "    # Get total number of columns\n",
    "    total_cols = df.shape[1]\n",
    "    # Calculate how many groups of 9 features we have\n",
    "    num_groups = total_cols // num_features\n",
    "    \n",
    "    # Create a list of column indices to keep\n",
    "    cols_to_keep = []\n",
    "    for i in range(num_groups):\n",
    "        inx = i * num_features + pos\n",
    "        cols_to_keep.append(inx)\n",
    "    \n",
    "    # Keep only the selected columns\n",
    "    df = df.iloc[:, cols_to_keep]\n",
    "    reshaped_df = df.values.reshape(df.shape[0], df.shape[1], 1)\n",
    "    \n",
    "    return reshaped_df\n",
    "feature_path = r'/home/chanan/Dataset/50ms/5/5 classes/features.csv'\n",
    "label_path = r'/home/chanan/Dataset/50ms/5/5 classes/labels.csv'\n",
    "feature_df = pd.read_csv(filepath_or_buffer=feature_path)\n",
    "label_df = pd.read_csv(filepath_or_buffer=label_path)\n",
    "\n",
    "reshaped_labels = label_df.values.reshape(-1)\n",
    "print(reshaped_labels.shape)\n",
    "\n",
    "# Clean the labels\n",
    "def prepare_label(labels):\n",
    "#     reshaped_labels = labels.values.reshape(-1)\n",
    "    # Extract just the first number from each label string\n",
    "    cleaned = np.array([int(label.split()[1]) for label in labels])\n",
    "    y = cleaned.astype(np.int64)\n",
    "    if len(y.shape) > 1:\n",
    "        y = y.ravel()  # Flatten if needed\n",
    "    return y\n",
    "\n",
    "pos = 1\n",
    "num_features = 9 \n",
    "X = drop_unused_features(feature_df, num_features, pos)\n",
    "\n",
    "y = prepare_label(reshaped_labels)  # Convert to int64 for PyTorch's CrossEntropyLoss\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# print(y.shape)\n",
    "# print(y)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66cb2768-efc6-4b54-b3cb-5f347f44e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, y, config, val_split=0.2):\n",
    "    batch_size = config.batch_size\n",
    "\n",
    "    print(\"Original X shape:\", X.shape)\n",
    "    \n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    print(\"Reshaped X shape:\", X.shape)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=val_split, random_state=32, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Create datasets - no need to reshape here since we did it above\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val))\n",
    "    \n",
    "    # Adjust DataLoader settings based on device\n",
    "    loader_args = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_workers': 4 if torch.cuda.is_available() else 2,\n",
    "        'pin_memory': torch.cuda.is_available(),\n",
    "    }\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_dataset, shuffle=False, **loader_args)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb903dd-601f-4467-b125-d6b777878836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (5737, 101, 1)\n",
      "Reshaped X shape: (5737, 1, 101)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_loader, val_loader = prepare_data(X, y, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f7725f-b5b1-4721-b076-05b6ea1b0d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/144 [00:00<?, ?it/s]/home/chanan/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/chanan/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 144/144 [00:06<00:00, 22.10it/s, loss=1.5344, acc=38.48%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.88it/s, loss=1.4848, acc=39.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5237, Train Acc: 38.48%\n",
      "Val Loss: 1.4436, Val Acc: 39.37%\n",
      "New best validation accuracy: 39.37%\n",
      "\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.15it/s, loss=1.4124, acc=38.48%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.12it/s, loss=1.3909, acc=41.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4026, Train Acc: 38.48%\n",
      "Val Loss: 1.3522, Val Acc: 41.38%\n",
      "New best validation accuracy: 41.38%\n",
      "\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.01it/s, loss=1.3392, acc=43.19%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.09it/s, loss=1.3242, acc=46.34%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3299, Train Acc: 43.19%\n",
      "Val Loss: 1.2875, Val Acc: 46.34%\n",
      "New best validation accuracy: 46.34%\n",
      "\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.25it/s, loss=1.2830, acc=47.53%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.89it/s, loss=1.2690, acc=52.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2741, Train Acc: 47.53%\n",
      "Val Loss: 1.2338, Val Acc: 52.61%\n",
      "New best validation accuracy: 52.61%\n",
      "\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.74it/s, loss=1.2351, acc=54.02%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.13it/s, loss=1.2207, acc=59.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2265, Train Acc: 54.02%\n",
      "Val Loss: 1.1868, Val Acc: 59.06%\n",
      "New best validation accuracy: 59.06%\n",
      "\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.15it/s, loss=1.1924, acc=59.86%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.01it/s, loss=1.1773, acc=65.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1842, Train Acc: 59.86%\n",
      "Val Loss: 1.1446, Val Acc: 65.24%\n",
      "New best validation accuracy: 65.24%\n",
      "\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.50it/s, loss=1.1537, acc=66.81%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.49it/s, loss=1.1378, acc=69.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1457, Train Acc: 66.81%\n",
      "Val Loss: 1.1062, Val Acc: 69.16%\n",
      "New best validation accuracy: 69.16%\n",
      "\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.79it/s, loss=1.1194, acc=69.08%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.80it/s, loss=1.1016, acc=74.65%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1116, Train Acc: 69.08%\n",
      "Val Loss: 1.0710, Val Acc: 74.65%\n",
      "New best validation accuracy: 74.65%\n",
      "\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.13it/s, loss=1.0878, acc=73.52%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.52it/s, loss=1.0678, acc=76.74%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0803, Train Acc: 73.52%\n",
      "Val Loss: 1.0381, Val Acc: 76.74%\n",
      "New best validation accuracy: 76.74%\n",
      "\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.72it/s, loss=1.0564, acc=75.88%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.18it/s, loss=1.0365, acc=77.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0490, Train Acc: 75.88%\n",
      "Val Loss: 1.0077, Val Acc: 77.61%\n",
      "New best validation accuracy: 77.61%\n",
      "\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.79it/s, loss=1.0283, acc=76.79%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.98it/s, loss=1.0072, acc=78.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0211, Train Acc: 76.79%\n",
      "Val Loss: 0.9792, Val Acc: 78.75%\n",
      "New best validation accuracy: 78.75%\n",
      "\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.18it/s, loss=1.0020, acc=78.40%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.27it/s, loss=0.9799, acc=79.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9950, Train Acc: 78.40%\n",
      "Val Loss: 0.9527, Val Acc: 79.70%\n",
      "New best validation accuracy: 79.70%\n",
      "\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.91it/s, loss=0.9776, acc=78.23%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.92it/s, loss=0.9542, acc=80.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9708, Train Acc: 78.23%\n",
      "Val Loss: 0.9277, Val Acc: 80.92%\n",
      "New best validation accuracy: 80.92%\n",
      "\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.08it/s, loss=0.9549, acc=79.21%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.93it/s, loss=0.9305, acc=81.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9483, Train Acc: 79.21%\n",
      "Val Loss: 0.9046, Val Acc: 81.36%\n",
      "New best validation accuracy: 81.36%\n",
      "\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.77it/s, loss=0.9334, acc=80.13%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.51it/s, loss=0.9078, acc=81.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9269, Train Acc: 80.13%\n",
      "Val Loss: 0.8826, Val Acc: 81.88%\n",
      "New best validation accuracy: 81.88%\n",
      "\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.22it/s, loss=0.9123, acc=79.89%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.76it/s, loss=0.8865, acc=82.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9059, Train Acc: 79.89%\n",
      "Val Loss: 0.8619, Val Acc: 82.14%\n",
      "New best validation accuracy: 82.14%\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.71it/s, loss=0.8945, acc=80.08%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.61it/s, loss=0.8664, acc=82.58%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8883, Train Acc: 80.08%\n",
      "Val Loss: 0.8424, Val Acc: 82.58%\n",
      "New best validation accuracy: 82.58%\n",
      "\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.15it/s, loss=0.8772, acc=80.30%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.44it/s, loss=0.8477, acc=82.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8711, Train Acc: 80.30%\n",
      "Val Loss: 0.8241, Val Acc: 82.75%\n",
      "New best validation accuracy: 82.75%\n",
      "\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.85it/s, loss=0.8600, acc=80.91%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.13it/s, loss=0.8296, acc=83.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8540, Train Acc: 80.91%\n",
      "Val Loss: 0.8066, Val Acc: 83.01%\n",
      "New best validation accuracy: 83.01%\n",
      "\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.77it/s, loss=0.8414, acc=80.95%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.38it/s, loss=0.8128, acc=83.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8356, Train Acc: 80.95%\n",
      "Val Loss: 0.7903, Val Acc: 83.10%\n",
      "New best validation accuracy: 83.10%\n",
      "\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.10it/s, loss=0.8255, acc=81.61%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.36it/s, loss=0.7966, acc=83.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8197, Train Acc: 81.61%\n",
      "Val Loss: 0.7745, Val Acc: 83.10%\n",
      "\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.50it/s, loss=0.8087, acc=82.07%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.37it/s, loss=0.7810, acc=83.62%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8031, Train Acc: 82.07%\n",
      "Val Loss: 0.7593, Val Acc: 83.62%\n",
      "New best validation accuracy: 83.62%\n",
      "\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.33it/s, loss=0.7987, acc=81.96%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.19it/s, loss=0.7665, acc=83.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7932, Train Acc: 81.96%\n",
      "Val Loss: 0.7452, Val Acc: 83.89%\n",
      "New best validation accuracy: 83.89%\n",
      "\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.42it/s, loss=0.7818, acc=82.65%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.21it/s, loss=0.7525, acc=83.89%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7764, Train Acc: 82.65%\n",
      "Val Loss: 0.7316, Val Acc: 83.89%\n",
      "\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.88it/s, loss=0.7741, acc=82.20%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.44it/s, loss=0.7394, acc=83.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7687, Train Acc: 82.20%\n",
      "Val Loss: 0.7188, Val Acc: 83.97%\n",
      "New best validation accuracy: 83.97%\n",
      "\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.79it/s, loss=0.7620, acc=81.96%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.37it/s, loss=0.7272, acc=84.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7567, Train Acc: 81.96%\n",
      "Val Loss: 0.7070, Val Acc: 84.15%\n",
      "New best validation accuracy: 84.15%\n",
      "\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.66it/s, loss=0.7473, acc=82.37%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.10it/s, loss=0.7151, acc=84.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7421, Train Acc: 82.37%\n",
      "Val Loss: 0.6953, Val Acc: 84.15%\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.44it/s, loss=0.7367, acc=82.00%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.58it/s, loss=0.7034, acc=84.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7316, Train Acc: 82.00%\n",
      "Val Loss: 0.6838, Val Acc: 84.41%\n",
      "New best validation accuracy: 84.41%\n",
      "\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.74it/s, loss=0.7299, acc=83.00%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.59it/s, loss=0.6925, acc=84.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7248, Train Acc: 83.00%\n",
      "Val Loss: 0.6732, Val Acc: 84.41%\n",
      "\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.82it/s, loss=0.7143, acc=82.81%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.96it/s, loss=0.6820, acc=84.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7094, Train Acc: 82.81%\n",
      "Val Loss: 0.6631, Val Acc: 84.32%\n",
      "\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.68it/s, loss=0.7078, acc=83.05%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.66it/s, loss=0.6719, acc=84.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7029, Train Acc: 83.05%\n",
      "Val Loss: 0.6533, Val Acc: 84.84%\n",
      "New best validation accuracy: 84.84%\n",
      "\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.80it/s, loss=0.7019, acc=82.17%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.81it/s, loss=0.6624, acc=84.84%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6970, Train Acc: 82.17%\n",
      "Val Loss: 0.6440, Val Acc: 84.84%\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.93it/s, loss=0.6904, acc=83.07%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.51it/s, loss=0.6531, acc=84.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6856, Train Acc: 83.07%\n",
      "Val Loss: 0.6349, Val Acc: 84.93%\n",
      "New best validation accuracy: 84.93%\n",
      "\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.85it/s, loss=0.6807, acc=83.40%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.19it/s, loss=0.6439, acc=84.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6759, Train Acc: 83.40%\n",
      "Val Loss: 0.6260, Val Acc: 84.93%\n",
      "\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.69it/s, loss=0.6720, acc=83.55%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.10it/s, loss=0.6353, acc=85.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6673, Train Acc: 83.55%\n",
      "Val Loss: 0.6177, Val Acc: 85.10%\n",
      "New best validation accuracy: 85.10%\n",
      "\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.80it/s, loss=0.6653, acc=83.37%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.12it/s, loss=0.6272, acc=85.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6606, Train Acc: 83.37%\n",
      "Val Loss: 0.6098, Val Acc: 85.02%\n",
      "\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.53it/s, loss=0.6528, acc=83.70%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.44it/s, loss=0.6194, acc=85.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6482, Train Acc: 83.70%\n",
      "Val Loss: 0.6022, Val Acc: 85.54%\n",
      "New best validation accuracy: 85.54%\n",
      "\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.42it/s, loss=0.6506, acc=82.89%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.38it/s, loss=0.6117, acc=85.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6461, Train Acc: 82.89%\n",
      "Val Loss: 0.5947, Val Acc: 85.71%\n",
      "New best validation accuracy: 85.71%\n",
      "\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.52it/s, loss=0.6440, acc=83.61%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.39it/s, loss=0.6044, acc=85.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6395, Train Acc: 83.61%\n",
      "Val Loss: 0.5876, Val Acc: 85.63%\n",
      "\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.71it/s, loss=0.6336, acc=83.68%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.16it/s, loss=0.5971, acc=85.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6292, Train Acc: 83.68%\n",
      "Val Loss: 0.5806, Val Acc: 85.71%\n",
      "\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 26.47it/s, loss=0.6259, acc=84.11%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.49it/s, loss=0.5906, acc=85.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6216, Train Acc: 84.11%\n",
      "Val Loss: 0.5742, Val Acc: 85.63%\n",
      "\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.19it/s, loss=0.6234, acc=83.85%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.27it/s, loss=0.5842, acc=85.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6190, Train Acc: 83.85%\n",
      "Val Loss: 0.5680, Val Acc: 85.71%\n",
      "\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.76it/s, loss=0.6148, acc=84.46%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.39it/s, loss=0.5775, acc=85.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6105, Train Acc: 84.46%\n",
      "Val Loss: 0.5614, Val Acc: 85.80%\n",
      "New best validation accuracy: 85.80%\n",
      "\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.40it/s, loss=0.6101, acc=84.16%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.21it/s, loss=0.5714, acc=86.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6058, Train Acc: 84.16%\n",
      "Val Loss: 0.5555, Val Acc: 86.15%\n",
      "New best validation accuracy: 86.15%\n",
      "\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.89it/s, loss=0.6022, acc=84.40%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.56it/s, loss=0.5655, acc=86.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5980, Train Acc: 84.40%\n",
      "Val Loss: 0.5498, Val Acc: 86.06%\n",
      "\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.62it/s, loss=0.5951, acc=84.40%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.17it/s, loss=0.5596, acc=86.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5910, Train Acc: 84.40%\n",
      "Val Loss: 0.5441, Val Acc: 86.15%\n",
      "\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.92it/s, loss=0.5909, acc=84.31%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.85it/s, loss=0.5539, acc=86.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5868, Train Acc: 84.31%\n",
      "Val Loss: 0.5385, Val Acc: 86.32%\n",
      "New best validation accuracy: 86.32%\n",
      "\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.47it/s, loss=0.5899, acc=84.79%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 24.23it/s, loss=0.5486, acc=86.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5858, Train Acc: 84.79%\n",
      "Val Loss: 0.5334, Val Acc: 86.24%\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.95it/s, loss=0.5833, acc=84.20%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.30it/s, loss=0.5434, acc=86.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5792, Train Acc: 84.20%\n",
      "Val Loss: 0.5283, Val Acc: 86.50%\n",
      "New best validation accuracy: 86.50%\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 144/144 [00:05<00:00, 25.57it/s, loss=0.5760, acc=85.01%]\n",
      "Validation: 100%|██████████| 36/36 [00:01<00:00, 23.61it/s, loss=0.5382, acc=86.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5720, Train Acc: 85.01%\n",
      "Val Loss: 0.5232, Val Acc: 86.50%\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "best_model = train_model(model, train_loader, val_loader, config)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(best_model, 'best_moment_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
